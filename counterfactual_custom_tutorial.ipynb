{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlYHRT4msXHh"
      },
      "source": [
        "#  <center> Counterfactual analysis tutorial2 <center>\n",
        "<center> Spring 2023 <center>\n",
        "<center> 3.C01/3.C51, 10.C01/10.C51, 20.C01/20.C51 <center>\n",
        "<center> No deadline, not graded <center>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uF2k0EYKsgn4"
      },
      "source": [
        "## 1. Predicting drug activity with Graph Convolutional Nets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnQUXBhvwtJO",
        "outputId": "838e5fe7-d066-4fac-ed0f-e36e6cc48b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rdkit in /Users/crystal/anaconda3/envs/cox/lib/python3.9/site-packages (2022.9.1)\n",
            "Requirement already satisfied: Pillow in /Users/crystal/anaconda3/envs/cox/lib/python3.9/site-packages (from rdkit) (9.1.1)\n",
            "Requirement already satisfied: numpy in /Users/crystal/anaconda3/envs/cox/lib/python3.9/site-packages (from rdkit) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eK9aNXlqtW7l"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/soojungy/miniconda3/envs/torchmd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import Descriptors,Crippen\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "\n",
        "from rdkit import RDLogger   \n",
        "RDLogger.DisableLog('rdApp.*') # turn off RDKit warning message "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISXPOcxFsWcG",
        "outputId": "1b8f529f-f4c4-4224-bb58-1b1234c57227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-08 13:33:09--  https://raw.githubusercontent.com/SoojungYang/ML4MolEng_Spring2023/main/BACE_clean.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98109 (96K) [text/plain]\n",
            "Saving to: ‘BACE_clean.csv’\n",
            "\n",
            "BACE_clean.csv      100%[===================>]  95.81K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2023-05-08 13:33:10 (12.1 MB/s) - ‘BACE_clean.csv’ saved [98109/98109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading BACE dataset\n",
        "! wget https://raw.githubusercontent.com/SoojungYang/ML4MolEng_Spring2023/main/BACE_clean.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnPc0ZBJwpex"
      },
      "source": [
        "A smiles to graph conversion function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NquIU4Uuwoq8"
      },
      "outputs": [],
      "source": [
        "def smiles2graph(smiles):\n",
        "    '''\n",
        "    Transform smiles into a list of atomic numbers and an edge array\n",
        "    \n",
        "    Args: \n",
        "        smiles (str): SMILES strings\n",
        "    \n",
        "    Returns: \n",
        "        z(np.array), A (np.array): list of atomic numbers, edge array\n",
        "    '''\n",
        "    \n",
        "    mol = Chem.MolFromSmiles( smiles ) # no hydrogen \n",
        "    z = np.array( [atom.GetAtomicNum() for atom in mol.GetAtoms()])\n",
        "    A = np.stack(Chem.GetAdjacencyMatrix(mol)).nonzero()\n",
        "    \n",
        "    return z, A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8GCKzMPwW98"
      },
      "source": [
        "Read the dataframe, shuffle its rows, and store its properties as lists. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRbNHoE_sfHi",
        "outputId": "70762b60-1768-4f03-8136-8b057867fc08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1182567/2121260417.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
            "  Edge_list.append(torch.LongTensor(a))\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"BACE_clean.csv\")\n",
        "df = shuffle(df).reset_index()\n",
        "\n",
        "AtomicNum_list = []\n",
        "Edge_list = []\n",
        "y_list = []\n",
        "Natom_list = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "        smiles = row.smiles\n",
        "        z, a = smiles2graph(smiles)\n",
        "\n",
        "        mol = Chem.MolFromSmiles( smiles ) \n",
        "        AtomicNum = torch.LongTensor(z)\n",
        "        AtomicNum_list.append(AtomicNum)\n",
        "        Edge_list.append(torch.LongTensor(a))\n",
        "        y_list.append(torch.FloatTensor([row.label]))\n",
        "        \n",
        "        Natom_list.append(len(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnBvxTvsseao",
        "outputId": "1532186d-6fcf-4b82-c0f0-fa5c18ec74c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of positive samples:  668\n",
            "number of negative samples:  814\n"
          ]
        }
      ],
      "source": [
        "# print the number of positive samples and the negative samples\n",
        "print(\"number of positive samples: \", len(df.loc[df.label==1]))\n",
        "print(\"number of negative samples: \", len(df.loc[df.label==0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m-JtdplwQge"
      },
      "source": [
        "A code for GNN classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "clSL8JTKvw0g"
      },
      "outputs": [],
      "source": [
        "class GraphDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,\n",
        "                 AtomicNum_list, \n",
        "                 Edge_list, \n",
        "                 Natom_list, \n",
        "                 y_list):\n",
        "        \n",
        "        '''\n",
        "        GraphDataset object\n",
        "        \n",
        "        Args: \n",
        "            z_list (list of torch.LongTensor)\n",
        "            a_list (list of torch.LongTensor)\n",
        "            N_list (list of int)\n",
        "            y_list (list of torch.FloatTensor)\n",
        "\n",
        "        '''\n",
        "        self.AtomicNum_list = AtomicNum_list # atomic number\n",
        "        self.Edge_list = Edge_list # edge list \n",
        "        self.Natom_list = Natom_list # Number of atoms \n",
        "        self.y_list = y_list # properties to predict \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Natom_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        AtomicNum = torch.LongTensor(self.AtomicNum_list[idx])\n",
        "        Edge = torch.LongTensor(self.Edge_list[idx])\n",
        "        Natom = self.Natom_list[idx]\n",
        "        y = torch.Tensor(self.y_list[idx])\n",
        "        \n",
        "        return AtomicNum, Edge, Natom, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kWXcRinMyoPr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "AtomicNum_train, AtomicNum_test, Edge_train, Edge_test, Natom_train, Natom_test, y_train, y_test = train_test_split(AtomicNum_list, \n",
        "                                                                                      Edge_list, \n",
        "                                                                                      Natom_list, \n",
        "                                                                                      y_list, test_size=0.2)\n",
        "\n",
        "AtomicNum_train, AtomicNum_val, Edge_train, Edge_val, Natom_train, Natom_val, y_train, y_val = train_test_split(AtomicNum_train, \n",
        "                                                                                      Edge_train, \n",
        "                                                                                      Natom_train, \n",
        "                                                                                      y_train, test_size=0.1/0.8)\n",
        "\n",
        "train_dataset = GraphDataset(AtomicNum_train, \n",
        "                            Edge_train, \n",
        "                            Natom_train,\n",
        "                            y_train)\n",
        "val_dataset = GraphDataset(AtomicNum_val,\n",
        "                          Edge_val, \n",
        "                          Natom_val, \n",
        "                          y_val)\n",
        "test_dataset =  GraphDataset(AtomicNum_test, \n",
        "                            Edge_test, \n",
        "                            Natom_test, \n",
        "                            y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uW4mAcfpx_I_"
      },
      "outputs": [],
      "source": [
        "# collage_graphs() function is used to batch multiple graphs into one batched graph\n",
        "# the function is used in the DataLoader to batch multiple graphs into one batched graph\n",
        "\n",
        "def collate_graphs(batch):\n",
        "    '''Batch multiple graphs into one batched graph\n",
        "    \n",
        "    Args:\n",
        "    \n",
        "        batch (tuple): tuples of AtomicNum, Edge, Natom and y obtained from GraphDataset.__getitem__() \n",
        "        \n",
        "    Return \n",
        "        (tuple): Batched AtomicNum, Edge, Natom, y\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    AtomicNum_batch = []\n",
        "    Edge_batch = []\n",
        "    Natom_batch = []\n",
        "    y_batch = []\n",
        "\n",
        "    cumulative_atoms = np.cumsum([0] + [b[2] for b in batch])[:-1]\n",
        "    \n",
        "    for i in range(len(batch)):\n",
        "        z, a, N, y = batch[i]\n",
        "        index_shift = cumulative_atoms[i]\n",
        "        a = a + index_shift\n",
        "        AtomicNum_batch.append(z) \n",
        "        Edge_batch.append(a)\n",
        "        Natom_batch.append(N)\n",
        "        y_batch.append(y)\n",
        "        \n",
        "    AtomicNum_batch = torch.cat(AtomicNum_batch)\n",
        "    Edge_batch = torch.cat(Edge_batch, dim=1)\n",
        "    Natom_batch = Natom_batch\n",
        "    y_batch = torch.cat(y_batch)\n",
        "    \n",
        "    return AtomicNum_batch, Edge_batch, Natom_batch, y_batch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jv9emkA_ykzc"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=64, \n",
        "                          collate_fn=collate_graphs,shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=64, \n",
        "                          collate_fn=collate_graphs,shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                          batch_size=64, \n",
        "                          collate_fn=collate_graphs,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IwQKyt1Oy9Kc"
      },
      "outputs": [],
      "source": [
        "from itertools import repeat\n",
        "def scatter_add(src, index, dim_size, dim=-1, fill_value=0):\n",
        "    \n",
        "    '''\n",
        "    Sums all values from the src tensor into out at the indices specified in the index \n",
        "    tensor along a given axis dim. \n",
        "    '''\n",
        "    \n",
        "    index_size = list(repeat(1, src.dim()))\n",
        "    index_size[dim] = src.size(dim)\n",
        "    index = index.view(index_size).expand_as(src)\n",
        "    \n",
        "    dim = range(src.dim())[dim]\n",
        "    out_size = list(src.size())\n",
        "    out_size[dim] = dim_size\n",
        "\n",
        "    out = src.new_full(out_size, fill_value)\n",
        "\n",
        "    return out.scatter_add_(dim, index, src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MBt9vbUxzGao"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import ModuleDict\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    '''\n",
        "        A GNN model \n",
        "    '''\n",
        "    def __init__(self, n_convs=3, n_embed=64):\n",
        "        super(GNN, self).__init__()\n",
        "        \n",
        "        self.atom_embed = nn.Embedding(100, n_embed)\n",
        "        self.convolutions = nn.ModuleList(\n",
        "            [ \n",
        "                ModuleDict({\n",
        "                    'update_mlp': nn.Sequential(nn.Linear(n_embed, n_embed), \n",
        "                                                nn.ReLU(), \n",
        "                                                nn.Linear(n_embed, n_embed)),\n",
        "                    'message_mlp': nn.Sequential(nn.Linear(n_embed, n_embed), \n",
        "                                                 nn.ReLU(), \n",
        "                                                 nn.Linear(n_embed, n_embed)) \n",
        "                })\n",
        "                for _ in range(n_convs)\n",
        "            ]\n",
        "            )\n",
        "        # Declare readout layers\n",
        "        self.readout = nn.Sequential(nn.Linear(n_embed, n_embed), nn.ReLU(), nn.Linear(n_embed, n_embed))\n",
        "        self.final_layer = nn.Sequential(nn.Linear(n_embed, n_embed), nn.ReLU(), nn.Linear(n_embed, 1), nn.Sigmoid())\n",
        "        \n",
        "    def forward(self, AtomicNum, Edge, Natom):\n",
        "        # Parametrize embedding \n",
        "        h = self.atom_embed(AtomicNum) #eqn. 1\n",
        "        for conv in self.convolutions:\n",
        "            msg = conv['message_mlp'](h[Edge[0]] * h[Edge[1]])\n",
        "            dh = conv['update_mlp'](scatter_add(msg, Edge[0], dim=0, dim_size=h.shape[0]))\n",
        "            h = h + dh \n",
        "        \n",
        "        # node wise output \n",
        "        node_out = self.readout(h)\n",
        "        # split nodes back to graphs \n",
        "        node_splits = torch.split(node_out, Natom)\n",
        "        output = torch.stack([i.sum(0) for i in node_splits])\n",
        "        output = self.final_layer(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BQQmOJbR1UVA"
      },
      "outputs": [],
      "source": [
        "# loop() function used to train and evaluate the model\n",
        "loss_fn = nn.BCELoss()\n",
        "def loop(model, loader, epoch, evaluation=False):\n",
        "    \n",
        "    if evaluation:\n",
        "        model.eval()\n",
        "        mode = \"eval\"\n",
        "    else:\n",
        "        model.train()\n",
        "        mode = 'train'\n",
        "    batch_losses = []\n",
        "    \n",
        "    # Define tqdm progress bar \n",
        "    tqdm_data = tqdm(loader, position=0, leave=True, desc='{} (epoch #{})'.format(mode, epoch))\n",
        "    \n",
        "    for data in tqdm_data:\n",
        "        \n",
        "        AtomicNumber, Edge, Natom, y = data \n",
        "        AtomicNumber = AtomicNumber.to(device)\n",
        "        Edge = Edge.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(AtomicNumber, Edge, Natom)\n",
        "        loss = loss_fn(pred.squeeze(), y)\n",
        "        \n",
        "        if not evaluation:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_losses.append(loss.item())\n",
        "\n",
        "        postfix = ['batch loss={:.3f}'.format(loss.item()) , \n",
        "                   'avg. loss={:.3f}'.format(np.array(batch_losses).mean())]\n",
        "        \n",
        "        tqdm_data.set_postfix_str(' '.join(postfix))\n",
        "    \n",
        "    return np.array(batch_losses).mean()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train a GNN classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aq9iMLP1WDs",
        "outputId": "bcacaade-276b-4b3f-9bdb-a1c334196634"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train (epoch #0): 100%|██████████| 17/17 [00:01<00:00, 12.30it/s, batch loss=0.656 avg. loss=0.731]\n",
            "eval (epoch #0): 100%|██████████| 3/3 [00:00<00:00, 87.42it/s, batch loss=0.690 avg. loss=0.731]\n",
            "train (epoch #1): 100%|██████████| 17/17 [00:00<00:00, 78.71it/s, batch loss=0.661 avg. loss=0.700]\n",
            "eval (epoch #1): 100%|██████████| 3/3 [00:00<00:00, 191.24it/s, batch loss=0.682 avg. loss=0.687]\n",
            "train (epoch #2): 100%|██████████| 17/17 [00:00<00:00, 77.60it/s, batch loss=0.665 avg. loss=0.674]\n",
            "eval (epoch #2): 100%|██████████| 3/3 [00:00<00:00, 115.48it/s, batch loss=0.614 avg. loss=0.676]\n",
            "train (epoch #3): 100%|██████████| 17/17 [00:00<00:00, 66.56it/s, batch loss=0.628 avg. loss=0.669]\n",
            "eval (epoch #3): 100%|██████████| 3/3 [00:00<00:00, 224.62it/s, batch loss=0.667 avg. loss=0.664]\n",
            "train (epoch #4): 100%|██████████| 17/17 [00:00<00:00, 78.60it/s, batch loss=0.601 avg. loss=0.663]\n",
            "eval (epoch #4): 100%|██████████| 3/3 [00:00<00:00, 183.82it/s, batch loss=0.738 avg. loss=0.682]\n",
            "train (epoch #5): 100%|██████████| 17/17 [00:00<00:00, 68.36it/s, batch loss=0.705 avg. loss=0.670]\n",
            "eval (epoch #5): 100%|██████████| 3/3 [00:00<00:00, 186.65it/s, batch loss=0.745 avg. loss=0.690]\n",
            "train (epoch #6): 100%|██████████| 17/17 [00:00<00:00, 91.55it/s, batch loss=0.557 avg. loss=0.665]\n",
            "eval (epoch #6): 100%|██████████| 3/3 [00:00<00:00, 234.64it/s, batch loss=0.567 avg. loss=0.642]\n",
            "train (epoch #7): 100%|██████████| 17/17 [00:00<00:00, 81.32it/s, batch loss=0.537 avg. loss=0.653]\n",
            "eval (epoch #7): 100%|██████████| 3/3 [00:00<00:00, 112.82it/s, batch loss=0.682 avg. loss=0.673]\n",
            "train (epoch #8): 100%|██████████| 17/17 [00:00<00:00, 69.61it/s, batch loss=0.692 avg. loss=0.660]\n",
            "eval (epoch #8): 100%|██████████| 3/3 [00:00<00:00, 161.90it/s, batch loss=0.688 avg. loss=0.685]\n",
            "train (epoch #9): 100%|██████████| 17/17 [00:00<00:00, 61.25it/s, batch loss=0.541 avg. loss=0.642]\n",
            "eval (epoch #9): 100%|██████████| 3/3 [00:00<00:00, 109.80it/s, batch loss=0.701 avg. loss=0.662]\n",
            "train (epoch #10): 100%|██████████| 17/17 [00:00<00:00, 76.43it/s, batch loss=0.552 avg. loss=0.639]\n",
            "eval (epoch #10): 100%|██████████| 3/3 [00:00<00:00, 204.35it/s, batch loss=0.577 avg. loss=0.627]\n",
            "train (epoch #11): 100%|██████████| 17/17 [00:00<00:00, 84.04it/s, batch loss=0.660 avg. loss=0.639]\n",
            "eval (epoch #11): 100%|██████████| 3/3 [00:00<00:00, 191.81it/s, batch loss=0.619 avg. loss=0.641]\n",
            "train (epoch #12): 100%|██████████| 17/17 [00:00<00:00, 67.10it/s, batch loss=0.593 avg. loss=0.630]\n",
            "eval (epoch #12): 100%|██████████| 3/3 [00:00<00:00, 213.17it/s, batch loss=0.665 avg. loss=0.649]\n",
            "train (epoch #13): 100%|██████████| 17/17 [00:00<00:00, 90.31it/s, batch loss=0.693 avg. loss=0.634]\n",
            "eval (epoch #13): 100%|██████████| 3/3 [00:00<00:00, 176.14it/s, batch loss=0.659 avg. loss=0.654]\n",
            "train (epoch #14): 100%|██████████| 17/17 [00:00<00:00, 71.47it/s, batch loss=0.594 avg. loss=0.620]\n",
            "eval (epoch #14): 100%|██████████| 3/3 [00:00<00:00, 221.13it/s, batch loss=0.567 avg. loss=0.613]\n",
            "train (epoch #15): 100%|██████████| 17/17 [00:00<00:00, 75.46it/s, batch loss=0.633 avg. loss=0.639]\n",
            "eval (epoch #15): 100%|██████████| 3/3 [00:00<00:00, 152.60it/s, batch loss=0.715 avg. loss=0.638]\n",
            "train (epoch #16): 100%|██████████| 17/17 [00:00<00:00, 68.16it/s, batch loss=0.751 avg. loss=0.606]\n",
            "eval (epoch #16): 100%|██████████| 3/3 [00:00<00:00, 209.64it/s, batch loss=0.608 avg. loss=0.621]\n",
            "train (epoch #17): 100%|██████████| 17/17 [00:00<00:00, 81.68it/s, batch loss=0.545 avg. loss=0.596]\n",
            "eval (epoch #17): 100%|██████████| 3/3 [00:00<00:00, 180.78it/s, batch loss=0.691 avg. loss=0.632]\n",
            "train (epoch #18): 100%|██████████| 17/17 [00:00<00:00, 78.31it/s, batch loss=0.718 avg. loss=0.590]\n",
            "eval (epoch #18): 100%|██████████| 3/3 [00:00<00:00, 98.14it/s, batch loss=0.754 avg. loss=0.624]\n",
            "train (epoch #19): 100%|██████████| 17/17 [00:00<00:00, 58.64it/s, batch loss=0.659 avg. loss=0.580]\n",
            "eval (epoch #19): 100%|██████████| 3/3 [00:00<00:00, 99.81it/s, batch loss=0.440 avg. loss=0.551]\n",
            "train (epoch #20): 100%|██████████| 17/17 [00:00<00:00, 85.61it/s, batch loss=0.621 avg. loss=0.578]\n",
            "eval (epoch #20): 100%|██████████| 3/3 [00:00<00:00, 188.07it/s, batch loss=0.637 avg. loss=0.590]\n",
            "train (epoch #21): 100%|██████████| 17/17 [00:00<00:00, 80.09it/s, batch loss=0.492 avg. loss=0.556]\n",
            "eval (epoch #21): 100%|██████████| 3/3 [00:00<00:00, 192.76it/s, batch loss=0.633 avg. loss=0.593]\n",
            "train (epoch #22): 100%|██████████| 17/17 [00:00<00:00, 59.99it/s, batch loss=0.632 avg. loss=0.554]\n",
            "eval (epoch #22): 100%|██████████| 3/3 [00:00<00:00, 108.99it/s, batch loss=0.776 avg. loss=0.626]\n",
            "train (epoch #23): 100%|██████████| 17/17 [00:00<00:00, 67.26it/s, batch loss=0.491 avg. loss=0.545]\n",
            "eval (epoch #23): 100%|██████████| 3/3 [00:00<00:00, 165.52it/s, batch loss=0.490 avg. loss=0.562]\n",
            "train (epoch #24): 100%|██████████| 17/17 [00:00<00:00, 83.08it/s, batch loss=0.582 avg. loss=0.537]\n",
            "eval (epoch #24): 100%|██████████| 3/3 [00:00<00:00, 200.75it/s, batch loss=0.454 avg. loss=0.583]\n",
            "train (epoch #25): 100%|██████████| 17/17 [00:00<00:00, 57.67it/s, batch loss=0.423 avg. loss=0.531]\n",
            "eval (epoch #25): 100%|██████████| 3/3 [00:00<00:00, 152.52it/s, batch loss=0.543 avg. loss=0.568]\n",
            "train (epoch #26): 100%|██████████| 17/17 [00:00<00:00, 73.25it/s, batch loss=0.454 avg. loss=0.513]\n",
            "eval (epoch #26): 100%|██████████| 3/3 [00:00<00:00, 193.63it/s, batch loss=0.700 avg. loss=0.601]\n",
            "train (epoch #27): 100%|██████████| 17/17 [00:00<00:00, 76.26it/s, batch loss=0.486 avg. loss=0.529]\n",
            "eval (epoch #27): 100%|██████████| 3/3 [00:00<00:00, 57.58it/s, batch loss=0.568 avg. loss=0.563]\n",
            "train (epoch #28): 100%|██████████| 17/17 [00:00<00:00, 61.63it/s, batch loss=0.344 avg. loss=0.520]\n",
            "eval (epoch #28): 100%|██████████| 3/3 [00:00<00:00, 198.42it/s, batch loss=0.503 avg. loss=0.547]\n",
            "train (epoch #29): 100%|██████████| 17/17 [00:00<00:00, 80.95it/s, batch loss=0.546 avg. loss=0.531]\n",
            "eval (epoch #29): 100%|██████████| 3/3 [00:00<00:00, 182.53it/s, batch loss=0.490 avg. loss=0.547]\n",
            "train (epoch #30): 100%|██████████| 17/17 [00:00<00:00, 62.68it/s, batch loss=0.436 avg. loss=0.528]\n",
            "eval (epoch #30): 100%|██████████| 3/3 [00:00<00:00, 104.19it/s, batch loss=0.463 avg. loss=0.546]\n",
            "train (epoch #31): 100%|██████████| 17/17 [00:00<00:00, 79.73it/s, batch loss=0.526 avg. loss=0.525]\n",
            "eval (epoch #31): 100%|██████████| 3/3 [00:00<00:00, 154.74it/s, batch loss=0.744 avg. loss=0.617]\n",
            "train (epoch #32): 100%|██████████| 17/17 [00:00<00:00, 69.78it/s, batch loss=0.401 avg. loss=0.526]\n",
            "eval (epoch #32): 100%|██████████| 3/3 [00:00<00:00, 122.37it/s, batch loss=0.480 avg. loss=0.542]\n",
            "train (epoch #33): 100%|██████████| 17/17 [00:00<00:00, 58.06it/s, batch loss=0.493 avg. loss=0.500]\n",
            "eval (epoch #33): 100%|██████████| 3/3 [00:00<00:00, 102.29it/s, batch loss=0.514 avg. loss=0.536]\n",
            "train (epoch #34): 100%|██████████| 17/17 [00:00<00:00, 75.12it/s, batch loss=0.339 avg. loss=0.491]\n",
            "eval (epoch #34): 100%|██████████| 3/3 [00:00<00:00, 189.05it/s, batch loss=0.469 avg. loss=0.533]\n",
            "train (epoch #35): 100%|██████████| 17/17 [00:00<00:00, 72.36it/s, batch loss=0.650 avg. loss=0.544]\n",
            "eval (epoch #35): 100%|██████████| 3/3 [00:00<00:00, 192.41it/s, batch loss=0.525 avg. loss=0.534]\n",
            "train (epoch #36): 100%|██████████| 17/17 [00:00<00:00, 69.98it/s, batch loss=0.470 avg. loss=0.512]\n",
            "eval (epoch #36): 100%|██████████| 3/3 [00:00<00:00, 217.72it/s, batch loss=0.588 avg. loss=0.550]\n",
            "train (epoch #37): 100%|██████████| 17/17 [00:00<00:00, 65.25it/s, batch loss=0.624 avg. loss=0.513]\n",
            "eval (epoch #37): 100%|██████████| 3/3 [00:00<00:00, 137.73it/s, batch loss=0.520 avg. loss=0.553]\n",
            "train (epoch #38): 100%|██████████| 17/17 [00:00<00:00, 59.69it/s, batch loss=0.516 avg. loss=0.509]\n",
            "eval (epoch #38): 100%|██████████| 3/3 [00:00<00:00, 154.11it/s, batch loss=0.464 avg. loss=0.524]\n",
            "train (epoch #39): 100%|██████████| 17/17 [00:00<00:00, 70.91it/s, batch loss=0.579 avg. loss=0.498]\n",
            "eval (epoch #39): 100%|██████████| 3/3 [00:00<00:00, 163.07it/s, batch loss=0.634 avg. loss=0.563]\n",
            "train (epoch #40): 100%|██████████| 17/17 [00:00<00:00, 71.10it/s, batch loss=0.690 avg. loss=0.504]\n",
            "eval (epoch #40): 100%|██████████| 3/3 [00:00<00:00, 177.08it/s, batch loss=0.733 avg. loss=0.596]\n",
            "train (epoch #41): 100%|██████████| 17/17 [00:00<00:00, 74.92it/s, batch loss=0.349 avg. loss=0.483]\n",
            "eval (epoch #41): 100%|██████████| 3/3 [00:00<00:00, 118.72it/s, batch loss=0.854 avg. loss=0.620]\n",
            "train (epoch #42): 100%|██████████| 17/17 [00:00<00:00, 69.19it/s, batch loss=0.423 avg. loss=0.480]\n",
            "eval (epoch #42): 100%|██████████| 3/3 [00:00<00:00, 235.52it/s, batch loss=0.451 avg. loss=0.512]\n",
            "train (epoch #43): 100%|██████████| 17/17 [00:00<00:00, 84.72it/s, batch loss=0.353 avg. loss=0.486]\n",
            "eval (epoch #43): 100%|██████████| 3/3 [00:00<00:00, 190.24it/s, batch loss=0.610 avg. loss=0.561]\n",
            "train (epoch #44): 100%|██████████| 17/17 [00:00<00:00, 72.92it/s, batch loss=0.506 avg. loss=0.477]\n",
            "eval (epoch #44): 100%|██████████| 3/3 [00:00<00:00, 193.88it/s, batch loss=0.638 avg. loss=0.561]\n",
            "train (epoch #45): 100%|██████████| 17/17 [00:00<00:00, 61.20it/s, batch loss=0.354 avg. loss=0.472]\n",
            "eval (epoch #45): 100%|██████████| 3/3 [00:00<00:00, 106.12it/s, batch loss=0.553 avg. loss=0.533]\n",
            "train (epoch #46): 100%|██████████| 17/17 [00:00<00:00, 70.33it/s, batch loss=0.522 avg. loss=0.457]\n",
            "eval (epoch #46): 100%|██████████| 3/3 [00:00<00:00, 171.21it/s, batch loss=0.314 avg. loss=0.479]\n",
            "train (epoch #47): 100%|██████████| 17/17 [00:00<00:00, 72.63it/s, batch loss=0.582 avg. loss=0.472]\n",
            "eval (epoch #47): 100%|██████████| 3/3 [00:00<00:00, 227.91it/s, batch loss=0.840 avg. loss=0.590]\n",
            "train (epoch #48): 100%|██████████| 17/17 [00:00<00:00, 69.64it/s, batch loss=0.590 avg. loss=0.482]\n",
            "eval (epoch #48): 100%|██████████| 3/3 [00:00<00:00, 107.76it/s, batch loss=0.413 avg. loss=0.523]\n",
            "train (epoch #49): 100%|██████████| 17/17 [00:00<00:00, 69.60it/s, batch loss=0.584 avg. loss=0.483]\n",
            "eval (epoch #49): 100%|██████████| 3/3 [00:00<00:00, 175.55it/s, batch loss=0.907 avg. loss=0.639]\n",
            "train (epoch #50): 100%|██████████| 17/17 [00:00<00:00, 69.90it/s, batch loss=0.375 avg. loss=0.483]\n",
            "eval (epoch #50): 100%|██████████| 3/3 [00:00<00:00, 109.34it/s, batch loss=0.551 avg. loss=0.538]\n",
            "train (epoch #51): 100%|██████████| 17/17 [00:00<00:00, 65.89it/s, batch loss=0.460 avg. loss=0.459]\n",
            "eval (epoch #51): 100%|██████████| 3/3 [00:00<00:00, 174.29it/s, batch loss=0.371 avg. loss=0.479]\n",
            "train (epoch #52): 100%|██████████| 17/17 [00:00<00:00, 74.16it/s, batch loss=0.664 avg. loss=0.474]\n",
            "eval (epoch #52): 100%|██████████| 3/3 [00:00<00:00, 181.63it/s, batch loss=0.806 avg. loss=0.633]\n",
            "train (epoch #53): 100%|██████████| 17/17 [00:00<00:00, 69.13it/s, batch loss=0.702 avg. loss=0.494]\n",
            "eval (epoch #53): 100%|██████████| 3/3 [00:00<00:00, 90.91it/s, batch loss=0.498 avg. loss=0.511]\n",
            "train (epoch #54): 100%|██████████| 17/17 [00:00<00:00, 56.76it/s, batch loss=0.729 avg. loss=0.487]\n",
            "eval (epoch #54): 100%|██████████| 3/3 [00:00<00:00, 176.81it/s, batch loss=0.925 avg. loss=0.655]\n",
            "train (epoch #55): 100%|██████████| 17/17 [00:00<00:00, 75.94it/s, batch loss=0.243 avg. loss=0.478]\n",
            "eval (epoch #55): 100%|██████████| 3/3 [00:00<00:00, 178.62it/s, batch loss=0.516 avg. loss=0.530]\n",
            "train (epoch #56): 100%|██████████| 17/17 [00:00<00:00, 66.74it/s, batch loss=0.180 avg. loss=0.441]\n",
            "eval (epoch #56): 100%|██████████| 3/3 [00:00<00:00, 82.84it/s, batch loss=0.607 avg. loss=0.552]\n",
            "train (epoch #57): 100%|██████████| 17/17 [00:00<00:00, 67.29it/s, batch loss=0.448 avg. loss=0.433]\n",
            "eval (epoch #57): 100%|██████████| 3/3 [00:00<00:00, 170.22it/s, batch loss=0.359 avg. loss=0.483]\n",
            "train (epoch #58): 100%|██████████| 17/17 [00:00<00:00, 78.02it/s, batch loss=0.366 avg. loss=0.438]\n",
            "eval (epoch #58): 100%|██████████| 3/3 [00:00<00:00, 167.98it/s, batch loss=0.480 avg. loss=0.525]\n",
            "train (epoch #59): 100%|██████████| 17/17 [00:00<00:00, 68.91it/s, batch loss=0.270 avg. loss=0.421]\n",
            "eval (epoch #59): 100%|██████████| 3/3 [00:00<00:00, 115.57it/s, batch loss=0.563 avg. loss=0.588]\n",
            "train (epoch #60): 100%|██████████| 17/17 [00:00<00:00, 59.49it/s, batch loss=0.867 avg. loss=0.452]\n",
            "eval (epoch #60): 100%|██████████| 3/3 [00:00<00:00, 163.45it/s, batch loss=0.419 avg. loss=0.510]\n",
            "train (epoch #61): 100%|██████████| 17/17 [00:00<00:00, 69.12it/s, batch loss=0.526 avg. loss=0.456]\n",
            "eval (epoch #61): 100%|██████████| 3/3 [00:00<00:00, 160.33it/s, batch loss=0.474 avg. loss=0.519]\n",
            "train (epoch #62): 100%|██████████| 17/17 [00:00<00:00, 62.26it/s, batch loss=0.339 avg. loss=0.427]\n",
            "eval (epoch #62): 100%|██████████| 3/3 [00:00<00:00, 177.94it/s, batch loss=0.568 avg. loss=0.509]\n",
            "train (epoch #63): 100%|██████████| 17/17 [00:00<00:00, 75.55it/s, batch loss=0.489 avg. loss=0.422]\n",
            "eval (epoch #63): 100%|██████████| 3/3 [00:00<00:00, 179.31it/s, batch loss=0.595 avg. loss=0.527]\n",
            "train (epoch #64): 100%|██████████| 17/17 [00:00<00:00, 71.59it/s, batch loss=0.343 avg. loss=0.408]\n",
            "eval (epoch #64): 100%|██████████| 3/3 [00:00<00:00, 195.22it/s, batch loss=0.675 avg. loss=0.564]\n",
            "train (epoch #65): 100%|██████████| 17/17 [00:00<00:00, 66.72it/s, batch loss=0.487 avg. loss=0.434]\n",
            "eval (epoch #65): 100%|██████████| 3/3 [00:00<00:00, 90.78it/s, batch loss=0.599 avg. loss=0.523]\n",
            "train (epoch #66): 100%|██████████| 17/17 [00:00<00:00, 74.23it/s, batch loss=0.686 avg. loss=0.428]\n",
            "eval (epoch #66): 100%|██████████| 3/3 [00:00<00:00, 172.47it/s, batch loss=0.557 avg. loss=0.519]\n",
            "train (epoch #67): 100%|██████████| 17/17 [00:00<00:00, 60.12it/s, batch loss=0.512 avg. loss=0.431]\n",
            "eval (epoch #67): 100%|██████████| 3/3 [00:00<00:00, 161.67it/s, batch loss=0.486 avg. loss=0.499]\n",
            "train (epoch #68): 100%|██████████| 17/17 [00:00<00:00, 68.83it/s, batch loss=0.294 avg. loss=0.418]\n",
            "eval (epoch #68): 100%|██████████| 3/3 [00:00<00:00, 171.19it/s, batch loss=0.652 avg. loss=0.565]\n",
            "train (epoch #69): 100%|██████████| 17/17 [00:00<00:00, 73.55it/s, batch loss=0.320 avg. loss=0.416]\n",
            "eval (epoch #69): 100%|██████████| 3/3 [00:00<00:00, 165.69it/s, batch loss=0.926 avg. loss=0.601]\n",
            "train (epoch #70): 100%|██████████| 17/17 [00:00<00:00, 61.63it/s, batch loss=0.251 avg. loss=0.395]\n",
            "eval (epoch #70): 100%|██████████| 3/3 [00:00<00:00, 115.41it/s, batch loss=0.366 avg. loss=0.466]\n",
            "train (epoch #71): 100%|██████████| 17/17 [00:00<00:00, 70.83it/s, batch loss=0.464 avg. loss=0.402]\n",
            "eval (epoch #71): 100%|██████████| 3/3 [00:00<00:00, 129.88it/s, batch loss=0.691 avg. loss=0.592]\n",
            "train (epoch #72): 100%|██████████| 17/17 [00:00<00:00, 76.97it/s, batch loss=0.547 avg. loss=0.396]\n",
            "eval (epoch #72): 100%|██████████| 3/3 [00:00<00:00, 189.34it/s, batch loss=0.270 avg. loss=0.461]\n",
            "train (epoch #73): 100%|██████████| 17/17 [00:00<00:00, 69.59it/s, batch loss=0.600 avg. loss=0.408]\n",
            "eval (epoch #73): 100%|██████████| 3/3 [00:00<00:00, 105.75it/s, batch loss=0.505 avg. loss=0.504]\n",
            "train (epoch #74): 100%|██████████| 17/17 [00:00<00:00, 66.92it/s, batch loss=0.415 avg. loss=0.421]\n",
            "eval (epoch #74): 100%|██████████| 3/3 [00:00<00:00, 179.99it/s, batch loss=0.518 avg. loss=0.494]\n",
            "train (epoch #75): 100%|██████████| 17/17 [00:00<00:00, 77.24it/s, batch loss=0.620 avg. loss=0.402]\n",
            "eval (epoch #75): 100%|██████████| 3/3 [00:00<00:00, 173.42it/s, batch loss=0.575 avg. loss=0.525]\n",
            "train (epoch #76): 100%|██████████| 17/17 [00:00<00:00, 57.13it/s, batch loss=0.152 avg. loss=0.381]\n",
            "eval (epoch #76): 100%|██████████| 3/3 [00:00<00:00, 141.67it/s, batch loss=0.296 avg. loss=0.497]\n",
            "train (epoch #77): 100%|██████████| 17/17 [00:00<00:00, 69.10it/s, batch loss=0.376 avg. loss=0.388]\n",
            "eval (epoch #77): 100%|██████████| 3/3 [00:00<00:00, 193.26it/s, batch loss=0.682 avg. loss=0.551]\n",
            "train (epoch #78): 100%|██████████| 17/17 [00:00<00:00, 80.21it/s, batch loss=0.192 avg. loss=0.370]\n",
            "eval (epoch #78): 100%|██████████| 3/3 [00:00<00:00, 106.07it/s, batch loss=0.714 avg. loss=0.640]\n",
            "train (epoch #79): 100%|██████████| 17/17 [00:00<00:00, 73.24it/s, batch loss=0.497 avg. loss=0.409]\n",
            "eval (epoch #79): 100%|██████████| 3/3 [00:00<00:00, 106.87it/s, batch loss=0.645 avg. loss=0.521]\n"
          ]
        }
      ],
      "source": [
        "from torch import optim\n",
        "device = 'cuda:0'\n",
        "model = GNN(n_convs=3, n_embed=64).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=50, verbose=True)\n",
        "\n",
        "for epoch in range(80):    \n",
        "    train_loss = loop(model, train_loader, epoch)\n",
        "    val_loss = loop(model, val_loader, epoch, evaluation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgGZcNIaYGkj"
      },
      "source": [
        "Evaluate the model performance. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1HmXQAt513tB"
      },
      "outputs": [],
      "source": [
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    AtomicNumber, Edge, Natom, y = data \n",
        "    AtomicNumber = AtomicNumber.to(device)\n",
        "    Edge = Edge.to(device)\n",
        "    y = y.to(device)\n",
        "    pred = model(AtomicNumber, Edge, Natom)\n",
        "    y_true += y.squeeze().tolist()\n",
        "    \n",
        "    pred = (pred.squeeze()>0.5).tolist()\n",
        "    y_pred += pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "tPuOGAfl3kNT",
        "outputId": "c07c1d31-0948-4aa9-d0fe-cd3240a717e5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(conf_mat)\n",
        "\n",
        "ax.set_xticks(np.arange(2))\n",
        "ax.set_yticks(np.arange(2))\n",
        "\n",
        "ax.set_xticklabels([0, 1])\n",
        "ax.set_yticklabels([0, 1])\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        text = ax.text(j, i, conf_mat[i, j],\n",
        "                       ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1XOuget7At9",
        "outputId": "6065eac7-be49-4ca8-87db-f5dfa46254b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy 0.7710437710437711\n"
          ]
        }
      ],
      "source": [
        "print(\"accuracy\", (np.array(y_pred)==np.array(y_true)).sum()/len(y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0flw6zO7Ymov"
      },
      "source": [
        "## 2. Implement a custom counterfactual generator"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this project, we aim to develop a simple counterfactual generator for Graph Neural Networks (GNNs). Given a molecule and its true or predicted label, our objective is to generate a molecule that closely resembles the original molecule but has the opposite label.\n",
        "\n",
        "To achieve this, we propose a method where we iteratively flip the atomic number of a randomly selected atom in the molecule and evaluate the model's prediction. If the model predicts the counterfactual label, we add the candidate molecule to a list of potential counterfactuals.\n",
        "\n",
        "Once we have a list of potential counterfactuals, we transform the changed graphs into molecular objects and use the RDKit library to visualize the flipped atom. The resulting molecule with the highlighted flipped atom can then be analyzed by domain experts to assess its chemical plausibility and interpretability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "# we will use graph_to_mol() function to convert graph to molecule\n",
        "atom_dict = {  6: 'C', 7: 'N', 8: 'O', 9: 'F', \n",
        "               15: 'P', 16: 'S', 17: 'Cl', \n",
        "               35: 'Br', 53: 'I',}\n",
        "\n",
        "def graph_to_mol(x, Edge):\n",
        "  \"\"\"\n",
        "  x: Atomic Number\n",
        "  Edge: Edge List\n",
        "  \"\"\"\n",
        "  atom_one_hot = x.detach().cpu().numpy()\n",
        "\n",
        "  mol = Chem.RWMol() # generate empty mol object\n",
        "  for i, atom_num in enumerate(atom_one_hot):\n",
        "      atom_symbol = atom_dict[atom_num] # get atom symbol from atomic number\n",
        "      atom = Chem.Atom(atom_symbol) # create atom object\n",
        "      mol.AddAtom(atom) # add atom to mol object\n",
        "\n",
        "  edge_list = Edge.detach().cpu().numpy().transpose(1,0) # get edge list from the original molecule\n",
        "  for edge in edge_list:\n",
        "    i, j = edge\n",
        "    if i < j:\n",
        "      mol.AddBond(int(i), int(j), Chem.rdchem.BondType.UNSPECIFIED) # add bond to mol object\n",
        "  return Chem.RemoveHs(mol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DKL05n_1JlSl"
      },
      "outputs": [],
      "source": [
        "atom_list = torch.LongTensor([6, 7, 8, 9, 15, 16, 17, 35, 53])\n",
        "\n",
        "def generate_candidates(x, A, Natom, y, model, num_candidates=10):\n",
        "    \"\"\"Generates candidate molecules with flipped atomic numbers.\"\"\"\n",
        "    candidates = [] # list of tuples (mol, prob), where mol is a counterfactual molecule \n",
        "                    # and prob is the probability of the counterfactual molecule being an active molecule\n",
        "    \n",
        "    x, A, y = x.to(device), A.to(device), y.to(device) # original molecule\n",
        "    target_y = 1-y # counterfactual label\n",
        "\n",
        "    for i in range(num_candidates):\n",
        "        # Generate a random candidate molecule by flipping an atom\n",
        "        x_ = x.clone()\n",
        "        atom_idx = torch.randint(len(x), (1,)) # index of the atom to be flipped\n",
        "        new_atom = torch.randint(1, 9, (1,)) # new atomic number\n",
        "        x_[atom_idx] = atom_list[new_atom] # flip the atom\n",
        "\n",
        "        # Evaluate the candidate molecule using the GNN model\n",
        "        with torch.no_grad():\n",
        "            prob = model(x_, A, Natom)[0] # probability of the candidate molecule being an active molecule\n",
        "        \n",
        "        # If the candidate molecule has the counterfactual label, add it to the list of candidates\n",
        "        if (prob.item() > 0.5) == target_y.item(): \n",
        "            mol = graph_to_mol(x_, A) \n",
        "            candidates.append((mol, prob.item(), atom_idx))\n",
        "        \n",
        "    # Return the candidate molecules with the highest predicted probability of having the counterfactual label\n",
        "    return sorted(candidates, key=lambda x: x[1]*(target_y.item()-0.5), reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JLgyC7S59aMU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# randomly select a molecule from the test set\n",
        "AtomicNumber, Edge, Natom, y = test_loader.dataset.__getitem__(random.choices(range(len(test_loader.dataset)), k=1)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "print(y.item()) # label of the original molecule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "asJzmR7zLQ1U"
      },
      "outputs": [],
      "source": [
        "# generate counterfactual molecules\n",
        "candidates = generate_candidates(AtomicNumber, Edge, Natom, y, model, num_candidates=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kratW0kNzJe",
        "outputId": "c631bf92-a788-4028-fd3e-3b9e906f3ee3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(<rdkit.Chem.rdchem.Mol at 0x7f8c4166d430>,\n",
              "  0.00022889352112542838,\n",
              "  tensor([17])),\n",
              " (<rdkit.Chem.rdchem.Mol at 0x7f8c41600580>,\n",
              "  0.002324539003893733,\n",
              "  tensor([13])),\n",
              " (<rdkit.Chem.rdchem.Mol at 0x7f8c41600120>,\n",
              "  0.04616380110383034,\n",
              "  tensor([24])),\n",
              " (<rdkit.Chem.rdchem.Mol at 0x7f8c4166d4a0>,\n",
              "  0.09230900555849075,\n",
              "  tensor([18])),\n",
              " (<rdkit.Chem.rdchem.Mol at 0x7f8c4166dac0>, 0.10565964877605438, tensor([4]))]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "candidates[:5] \n",
        "# print the top 5 candidates.\n",
        "# Each candidate is a tuple (mol, prob, atom_idx), where mol is a counterfactual molecule,\n",
        "# prob is the probability of the counterfactual molecule being an active molecule,\n",
        "# and atom_idx is the index of the atom that was flipped to generate the counterfactual molecule.\n",
        "# The top 5 candidates have the highest probability of being inactive molecules,\n",
        "# as the original molecule is an active molecule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# generate an image of the original molecule\n",
        "# bond orders are not specified in this image\n",
        "# hydrogen atoms should be neglected when interpreting the image\n",
        "# the atom with the flipped atomic number is highlighted in red\n",
        "mol = graph_to_mol(AtomicNumber, Edge)\n",
        "img = Draw.MolToImage(mol, removeHs=True, highlightAtoms=[candidates[0][-1].item()])\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Zt_mdf4LUXfo",
        "outputId": "66c3047f-1bea-4d87-b178-39cb0d4258c1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# generate an image of the top 1 candidate molecule\n",
        "# bond orders are not specified in this image\n",
        "# hydrogen atoms should be neglected when interpreting the image\n",
        "# the atom that was flipped is highlighted in red\n",
        "img = Draw.MolToImage(candidates[0][0], removeHs=True, highlightAtoms=[candidates[0][-1].item()])\n",
        "img"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
